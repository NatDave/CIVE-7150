{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12NnrQp6j1iMZAi8d8MvrmmE7phUjYc0Q","timestamp":1708436025941}],"authorship_tag":"ABX9TyO1IjcBBi6PtheReBmhwAcr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","import warnings     # filter warning messages\n","warnings.simplefilter(action=\"ignore\")\n","\n","def calc_metrics(y_true, y_pred):\n","    \"\"\"\n","    Calculate Mean Squared Error (MSE) and R-squared (R^2) score.\n","    \"\"\"\n","    mse = np.mean((y_true - y_pred) ** 2)\n","    r2 = 1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n","    return mse, r2\n","\n","def ridge_gradient_descent(X, y, alpha, lambda_, num_iterations):\n","    \"\"\"\n","    Perform gradient descent with Ridge Regression.\n","    \"\"\"\n","    num_samples, num_features = X.shape\n","    theta = np.zeros(num_features + 1)  # Initialize model parameters to zero, including intercept\n","\n","    # Insert a column of ones at the beginning of X (intercept term)\n","    X_with_intercept = np.hstack([np.ones((num_samples, 1)), X])\n","\n","    for _ in range(num_iterations):\n","        # Calculate predictions\n","        y_pred = X_with_intercept @ theta\n","\n","        # Calculate gradients with Ridge penalty\n","        gradients = -(2/num_samples) * X_with_intercept.T @ (y - y_pred) + 2 * lambda_ * theta\n","\n","        # Update parameters\n","        theta -= alpha * gradients\n","\n","    return theta\n","\n","# Read and preprocess the data\n","house_data_train = pd.read_csv('train.csv').drop(columns=['Unnamed: 0', 'zipcode'])\n","house_data_test = pd.read_csv('test.csv').drop(columns=['Unnamed: 0', 'id', 'date', 'zipcode'])\n","\n","# Make copies of the original data\n","house_data_train_nz = house_data_train.copy()\n","house_data_test_nz = house_data_test.copy()\n","\n","# Normalize all columns except the first one\n","scaler = StandardScaler()\n","house_data_train_nz.iloc[:, 1:] = scaler.fit_transform(house_data_train_nz.iloc[:, 1:])\n","house_data_test_nz.iloc[:, 1:] = scaler.transform(house_data_test_nz.iloc[:, 1:])\n","\n","# Divide values of the first column by 1000\n","house_data_train_nz.iloc[:, 0] /= 1000\n","house_data_test_nz.iloc[:, 0] /= 1000\n","\n","# Assign response variable (y) and features (X) for training and test data\n","y_train = house_data_train_nz.iloc[:, 0]\n","X_train = house_data_train_nz.iloc[:, 1:]\n","\n","y_test = house_data_test_nz.iloc[:, 0]\n","X_test = house_data_test_nz.iloc[:, 1:]\n","\n","# Define learning rates, lambda (regularization parameter), and number of iterations\n","learning_rates = [0.01, 0.1, 0.5]\n","lambda_values = [0.1, 0.5, 1.0]\n","num_iterations_list = [10, 50, 100]\n","\n","# Initialize results dictionary\n","results_ridge = {'Learning Rate': [], 'Lambda': [], 'Num Iterations': [],\n","           'MSE Train': [], 'R2 Train': [],\n","           'MSE Test': [], 'R2 Test': []}\n","\n","# Iterate over learning rates, lambda values, and number of iterations\n","for alpha in learning_rates:\n","    for lambda_ in lambda_values:\n","        for num_iterations in num_iterations_list:\n","            # Perform gradient descent with Ridge Regression\n","            theta = ridge_gradient_descent(X_train.values, y_train.values, alpha, lambda_, num_iterations)\n","\n","            # Predict on the training set\n","            y_train_pred = np.hstack([np.ones((len(X_train), 1)), X_train.values]) @ theta\n","\n","            # Calculate evaluation metrics for training set\n","            mse_train, r2_train = calc_metrics(y_train, y_train_pred)\n","\n","            # Predict on the test set\n","            y_test_pred = np.hstack([np.ones((len(X_test), 1)), X_test.values]) @ theta\n","\n","            # Calculate evaluation metrics for testing set\n","            mse_test, r2_test = calc_metrics(y_test, y_test_pred)\n","\n","            # Append results to the dictionary\n","            results_ridge['Learning Rate'].append(alpha)\n","            results_ridge['Lambda'].append(lambda_)\n","            results_ridge['Num Iterations'].append(num_iterations)\n","            results_ridge['MSE Train'].append(mse_train)\n","            results_ridge['R2 Train'].append(r2_train)\n","            results_ridge['MSE Test'].append(mse_test)\n","            results_ridge['R2 Test'].append(r2_test)\n","\n","# Create a DataFrame from the results dictionary\n","results_ridge_df = pd.DataFrame(results_ridge)\n","\n","# Display the results\n","print(results_ridge_df)"],"metadata":{"id":"u9QlyeveoPRL","executionInfo":{"status":"ok","timestamp":1708530574237,"user_tz":300,"elapsed":573,"user":{"displayName":"Nathan David Obeng-Amoako","userId":"11953631724850969111"}},"outputId":"2ccfef38-4428-4b3f-d427-fa68a57f7dc9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    Learning Rate  Lambda  Num Iterations      MSE Train       R2 Train  \\\n","0            0.01     0.1              10   2.367367e+05  -1.056128e+00   \n","1            0.01     0.1              50   7.538151e+04   3.452895e-01   \n","2            0.01     0.1             100   4.207005e+04   6.346094e-01   \n","3            0.01     0.5              10   2.407107e+05  -1.090643e+00   \n","4            0.01     0.5              50   9.847663e+04   1.447017e-01   \n","5            0.01     0.5             100   7.081337e+04   3.849652e-01   \n","6            0.01     1.0              10   2.455374e+05  -1.132564e+00   \n","7            0.01     1.0              50   1.261911e+05  -9.600672e-02   \n","8            0.01     1.0             100   1.086283e+05   5.653107e-02   \n","9            0.10     0.1              10   3.978950e+04   6.544166e-01   \n","10           0.10     0.1              50   3.397708e+04   7.048991e-01   \n","11           0.10     0.1             100   3.396428e+04   7.050103e-01   \n","12           0.10     0.5              10   6.817681e+04   4.078644e-01   \n","13           0.10     0.5              50   6.444516e+04   4.402750e-01   \n","14           0.10     0.5             100   6.444502e+04   4.402762e-01   \n","15           0.10     1.0              10   1.070659e+05   7.010106e-02   \n","16           0.10     1.0              50   1.061931e+05   7.768207e-02   \n","17           0.10     1.0             100   1.061931e+05   7.768207e-02   \n","18           0.50     0.1              10   2.241819e+17  -1.947085e+12   \n","19           0.50     0.1              50   1.268747e+68  -1.101944e+63   \n","20           0.50     0.1             100  3.502220e+131 -3.041780e+126   \n","21           0.50     0.5              10   1.144188e+18  -9.937603e+12   \n","22           0.50     0.5              50   7.856371e+71  -6.823488e+66   \n","23           0.50     0.5             100  1.552844e+139 -1.348691e+134   \n","24           0.50     1.0              10   7.278352e+18  -6.321461e+13   \n","25           0.50     1.0              50   1.601688e+76  -1.391113e+71   \n","26           0.50     1.0             100  7.634123e+147 -6.630459e+142   \n","\n","         MSE Test        R2 Test  \n","0    2.817830e+05  -6.900865e-01  \n","1    1.033507e+05   3.801198e-01  \n","2    6.907661e+04   5.856902e-01  \n","3    2.865626e+05  -7.187538e-01  \n","4    1.290546e+05   2.259521e-01  \n","5    1.003586e+05   3.980659e-01  \n","6    2.923614e+05  -7.535341e-01  \n","7    1.599452e+05   4.067608e-02  \n","8    1.416413e+05   1.504595e-01  \n","9    6.677408e+04   5.995004e-01  \n","10   6.068213e+04   6.360389e-01  \n","11   6.064183e+04   6.362806e-01  \n","12   9.765251e+04   4.142968e-01  \n","13   9.379333e+04   4.374435e-01  \n","14   9.379299e+04   4.374455e-01  \n","15   1.400303e+05   1.601219e-01  \n","16   1.391263e+05   1.655440e-01  \n","17   1.391263e+05   1.655440e-01  \n","18   2.503563e+17  -1.501595e+12  \n","19   1.416880e+68  -8.498207e+62  \n","20  3.911122e+131 -2.345825e+126  \n","21   1.277777e+18  -7.663892e+12  \n","22   8.773644e+71  -5.262283e+66  \n","23  1.734147e+139 -1.040112e+134  \n","24   8.128130e+18  -4.875115e+13  \n","25   1.788694e+76  -1.072828e+71  \n","26  8.525447e+147 -5.113419e+142  \n"]}]}]}